{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load all the pig dicom data and convert them to nifti",
   "id": "894ea1f31ad36796"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "9b38245d338462cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# !pip install loguru pydicom scipy scikit-image\n",
    "\n",
    "# !pip install git+https://github.com/mjirik/io3d --upgrade --force-reinstall\n",
    "# !pip install git+https://github.com/mjirik/imma --upgrade --force-reinstall\n",
    "\n",
    "# !pip install git+https://github.com/mjirik/io3d\n",
    "# !pip install git+https://github.com/mjirik/imma\n",
    "\n"
   ],
   "id": "a25c7d87e0d6f6e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import io3d\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "from pprint import pprint, pformat\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "logger.enable(\"io3d\")\n",
    "force = True\n",
    "# force = False\n",
    "\n",
    "recreate_meta = False\n",
    "recreate_meta = True\n",
    "# base_path = Path(r\"H:\\biomedical\\orig\\pilsen_pigs_all\\transplantation_dicom\")\n",
    "# dirname = \"Prasata DC\"\n",
    "# dirname = \"Prasata H\"\n",
    "dataset_base_path = Path(r\"~/mnt/nas-bmc3_ct/\").expanduser().resolve()\n",
    "# base_path = dataset_base_path / dirname\n",
    "base_path = dataset_base_path\n",
    "# fn_prefix = dirname.replace(\" \", '_') + \"-\"\n",
    "# output_dir_part = dirname.replace(\" \", '_')\n",
    "# base_path = Path(r\"~/Downloads/_temp/\").expanduser()  #: used when the zip files are downloaded manually\n",
    "# raw_path = Path(r\"H:\\biomedical\\orig\\pilsen_pigs_all\\transplantation_nii_transposed\")\n",
    "# transposed_path = Path(r\"H:\\biomedical\\orig\\pilsen_pigs_all\\transplantation_nii_transposed\")\n",
    "# output_path = Path(r\"H:\\biomedical\\orig\\pilsen_pigs\")\n",
    "# output_path= Path(r\"~/mnt/nas-bmc3_ct/pilsen_pigs_all/transplantation_nii_transposed\").expanduser() / output_dir_part\n",
    "metadata_path=dataset_base_path / \"metadata.csv\"\n",
    "\n",
    "assert base_path.exists()"
   ],
   "id": "a4c3a66ba976b797",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Convert all to nii",
   "id": "4412ef75511a347e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "\n",
   "id": "95e33f95037276d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def touch_file(pth:Path):\n",
    "    try:\n",
    "        with open(pth, \"rb\") as f:\n",
    "            # read just some part of the file\n",
    "            f.read(1)\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"Error in touching file {pth}: {e}\")\n",
    "        traceback.print_exc()"
   ],
   "id": "45829bc43eb70735",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from typing import Union\n",
    "\n",
    "def get_projection(\n",
    "        datap:io3d.image.DataPlus, axis:Union[int,str], method:str=\"max\"\n",
    "):\n",
    "    \"\"\"Get projection of 3D data to 2D.\"\"\"\n",
    "    if isinstance(axis, str):\n",
    "        dict_axis = {\"axial\": 0, \"coronal\": 1, \"sagittal\": 2}\n",
    "        if axis in dict_axis:\n",
    "            axis = dict_axis[axis]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown axis {axis}, use one of {list(dict_axis.keys())} or 0, 1, 2\")\n",
    "\n",
    "    data3d = datap.data3d\n",
    "    axcodes = datap.orientation_axcodes\n",
    "    data3d = io3d.image.transform_orientation(data3d, axcodes, \"SPL\")\n",
    "    if method == \"max\":\n",
    "        data2d = data3d.max(axis=axis)\n",
    "    elif method == \"mean\":\n",
    "        data2d = data3d.mean(axis=axis)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method {method}\")\n",
    "    return data2d\n",
    "\n"
   ],
   "id": "9a831c69193921ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# data2d = get_projection(datap, 0, \"max\")\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.style.use('classic')\n",
    "# plt.imshow(data2d, cmap=\"gray_r\")\n",
    "# plt.colorbar()\n",
    "# plt.style.available\n"
   ],
   "id": "7fd14c77d6a14097",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import tqdm",
   "id": "1a5ddd1d0a42e524",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import tqdm\n",
    "\n",
    "# List all directories under base_path (recursively)\n",
    "all_dirs = [p for p in base_path.rglob(\"*\") if p.is_dir() and \"Prasata \" in str(p)]\n",
    "\n",
    "leaf_dirs = []\n",
    "for d in tqdm.tqdm(all_dirs, desc=\"Checking dirs\"):\n",
    "    children = list(d.iterdir())\n",
    "    has_subdir = any(child.is_dir() for child in children)\n",
    "    has_file = any(child.is_file() for child in children)\n",
    "    if not has_subdir and has_file:\n",
    "        leaf_dirs.append(d)\n",
    "\n",
    "leaf_dirs\n",
    "\n",
    "\n",
    "\n",
    "# leaf_dirs = []\n",
    "# for d in tqdm.tqdm(list(base_path.glob(\"**/Prasata */**/\"))):\n",
    "#     if d.is_dir():\n",
    "#         # Get direct children\n",
    "#         children = list(d.iterdir())\n",
    "#         # Identify if there are any subdirectories\n",
    "#         has_subdir = any(child.is_dir() for child in children)\n",
    "#         # Identify if there is at least one file in the directory\n",
    "#         has_file = any(child.is_file() for child in children)\n",
    "#         # A leaf directory has no subdirectories but does contain files\n",
    "#         if not has_subdir and has_file:\n",
    "#             leaf_dirs.append(d)\n",
    "#\n",
    "# leaf_dirs"
   ],
   "id": "3c809fe6dfad1b3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "str(leaf_dirs[0].relative_to(base_path))",
   "id": "b95c367c8ffd12ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# io3d.read(sorted(leaf_dirs)[0], orientation_axcodes=\"IPL\")",
   "id": "f0bf2d2979a641c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "\n",
   "id": "29d6c4d963522918",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "201bb48d9964ae85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dir_path = sorted(leaf_dirs)[0]\n",
    "\n",
    "\n"
   ],
   "id": "701a3546bb0b04b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "current_fn = sorted(leaf_dirs)[0]\n",
    "\n",
    "def get_series_description(dcm_info, series_number):\n",
    "    series_description = \"\"\n",
    "    if \"SeriesDescription\" in dcm_info:\n",
    "        series_description = \" \" + dcm_info[\"SeriesDescription\"]\n",
    "\n",
    "    return str(series_number) + series_description\n",
    "\n",
    "def get_stats_of_series_in_dir(dir_path:str):\n",
    "    dicomdirectory = io3d.dcmreaddata.DicomDirectory(\n",
    "        str(dir_path)\n",
    "    )\n",
    "    return dicomdirectory.get_stats_of_series_in_dir()\n",
    "\n",
    "def get_stats_of_series_in_dir_nice_list(current_fn) -> list:\n",
    "    series_metadata = get_stats_of_series_in_dir(current_fn)\n",
    "    for kkey in series_metadata:\n",
    "        if \"dcmfilelist\" in series_metadata[kkey]:\n",
    "            # dir_info = series_metadata\n",
    "            series_metadata[kkey][\"dcmfilelist_len\"] = len(series_metadata[kkey][\"dcmfilelist\"])\n",
    "            series_metadata[kkey][\"dcmfilelist\"] = None\n",
    "\n",
    "\n",
    "        if \"SeriesNumber\" in series_metadata[kkey]:\n",
    "            series_metadata[kkey][\"SeriesNumber\"] = int(series_metadata[kkey][\"SeriesNumber\"])\n",
    "        if \"Count\" in series_metadata[kkey]:\n",
    "            series_metadata[kkey][\"Count\"] = int(series_metadata[kkey][\"Count\"])\n",
    "        series_metadata[kkey][\"Path\"] = str(current_fn)\n",
    "    series_metadata_list = list(series_metadata.values())\n",
    "    return series_metadata_list\n",
    "\n",
    "\n",
    "metadata_list = get_stats_of_series_in_dir_nice_list(current_fn)\n",
    "# metadata_list\n"
   ],
   "id": "c696843ba51e6ff6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bd301905871c7acf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections.abc import Iterable\n",
    "df = pd.DataFrame(metadata_list)\n",
    "# df['voxelsize_mm_0'] = df.voxelsize_mm.apply(lambda x: json.loads(x)[0] if isinstance(x, str) else x[0] if isinstance(x, list) else np.nan)\n",
    "# df['voxelsize_mm_1'] = df.voxelsize_mm.apply(lambda x: json.loads(x)[1] if isinstance(x, str) else np.nan)\n",
    "# df['voxelsize_mm_2'] = df.voxelsize_mm.apply(lambda x: json.loads(x)[2] if isinstance(x, str) else np.nan)\n",
    "# df['voxelsize_mm_2'] = df.voxelsize_mm.apply(lambda x: x[2] if len(x) == 3 else np.nan)\n",
    "df['voxelsize_mm_0'] = df.voxelsize_mm.apply(lambda x: x[0] if isinstance(x,Iterable) else np.nan)\n",
    "df['voxelsize_mm_1'] = df.voxelsize_mm.apply(lambda x: x[1] if isinstance(x,Iterable) else np.nan)\n",
    "df['voxelsize_mm_2'] = df.voxelsize_mm.apply(lambda x: x[2] if isinstance(x,Iterable) else np.nan)\n",
    "df"
   ],
   "id": "47bda8ab5ae91922",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# to utf-8 sig\n",
    "\n",
    "# df.to_csv(metadata_path, index=False, encoding=\"utf-8-sig\")"
   ],
   "id": "53964525669c6c14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metadata_list = []\n",
    "for current_fn in sorted(leaf_dirs):\n",
    "    metadata_ith = get_stats_of_series_in_dir_nice_list(current_fn)\n",
    "    metadata_list.extend(metadata_ith)\n"
   ],
   "id": "e34db927b16692b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(metadata_list)",
   "id": "e0a593a276e0fe24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# join csvs\n",
    "def append_dataframe_to_csv(df: pd.DataFrame, csv_filename: Path):\n",
    "    if csv_filename.exists():\n",
    "        existing_df = pd.read_csv(csv_filename)\n",
    "        # Combine using union of columns\n",
    "        combined_df = pd.concat([existing_df, df], ignore_index=True, sort=False)\n",
    "    else:\n",
    "        combined_df = df\n",
    "\n",
    "    # Save the combined data (overwriting the file)\n",
    "    combined_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "\n",
    "append_dataframe_to_csv(df, metadata_path)\n"
   ],
   "id": "91a0525787d07b4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "## STOP Here",
   "id": "ea78079acc448658",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # fnlist = list(base_path.glob(\"*Tx0*D_V*\"))\n",
    "# # find a leaf directory in base_path which contains some file\n",
    "#\n",
    "#\n",
    "#\n",
    "# # fnlist = sorted(list(base_path.glob(\"*Tx0*D_A*\")) + list(base_path.glob(\"*Tx0*D_V*\")))[::-1]\n",
    "# fnlist = sorted(leaf_dirs)\n",
    "#\n",
    "#\n",
    "# print(f\"Number of files: {len(fnlist)}\")\n",
    "# from joblib import Parallel, delayed\n",
    "# import tqdm\n",
    "# #\n",
    "# for fn in tqdm.tqdm(fnlist[4:]):\n",
    "#     # iterate over series\n",
    "#\n",
    "#     # dir_info = io3d.dcmreaddata.dicomdir_info(fn, gui=False)\n",
    "#     dir_info = get_stats_of_series_in_dir(fn)\n",
    "#\n",
    "#\n",
    "#     logger.debug(str(dir_info.keys()))\n",
    "#\n",
    "#     for series_number in dir_info.keys():\n",
    "#         if series_number == None:\n",
    "#             series_number = \"first\"\n",
    "#         # series_description = get_series_description(dir_info, series_number).replace(\" \", \"_\")\n",
    "#\n",
    "#         # i want to have there the parent directory\n",
    "#         # fn_name = str(fn.relative_to(base_path)).replace(\"\\\\\", \"-\").replace(\"/\", \"-\")\n",
    "#         fn_name = (fn_prefix + str(fn.relative_to(base_path))).replace(\"\\\\\", \"-\").replace(\"/\", \"-\").replace(\" \", \"_\")\n",
    "#         fn_name += f\"_{series_number}\"\n",
    "#\n",
    "#         # logger.info(fn)\n",
    "#         fn_in = fn\n",
    "#         # fn_out = raw_path / fn.name / f\"{fn.name}.mhd\"\n",
    "#         fn_out = output_path / fn_name / f\"{fn_name}.nii.gz\"\n",
    "#\n",
    "#         fn_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "#         fn_meta = fn_out.parent / \"meta.json\"\n",
    "#         if force or (not fn_out.exists()):\n",
    "#\n",
    "#             try:\n",
    "#                 fn_fns = sorted(list(fn.glob(\"*\")))\n",
    "#                 tqdm.tqdm.write(f\"Reading series {series_number} with {len(fn_fns)} files in {fn_in} and writing {fn_out}\")\n",
    "#                 # tqdm.tqdm.write(f\"Number of files in the directory: {len(fn_fns)}\")\n",
    "#                 # Parallel(n_jobs=2)(delayed(touch_file)(fn) for fn in tqdm.tqdm(fn_fns, desc=\"touching files\"))\n",
    "#\n",
    "#                 axcodes = \"IPL\"\n",
    "#                 # logger.debug(f\"Reading {fn_in} with axcodes={axcodes}\")\n",
    "#                 datap = io3d.read(fn_in,\n",
    "#                                   # series_number=\"first\",\n",
    "#                                   series_number=series_number,\n",
    "#                                   orientation_axcodes=axcodes)\n",
    "#                 # logger.debug(datap.keys())\n",
    "#                 io3d.write(datap, fn_out)\n",
    "#                 # logger.debug(\"writing done, creating projections\")\n",
    "#                 for axis in [\"axial\", \"coronal\", \"sagittal\"]:\n",
    "#                     data2d = get_projection(datap, axis, \"max\")\n",
    "#                     import skimage.io\n",
    "#                     # change intensity to range 0..1\n",
    "#\n",
    "#                     data2d = (255 * (data2d - np.min(data2d)).astype(float) / (np.max(data2d) - np.min(data2d))).astype(np.uint8)\n",
    "#                     skimage.io.imsave(fn_out.parent / f\"{fn_out.stem}_{axis}.jpg\", data2d)\n",
    "#                 # logger.debug(\"projections done\")\n",
    "#             except Exception as e:\n",
    "#                 import traceback\n",
    "#                 logger.error(f\"Error in reading {fn_in}: {e}\")\n",
    "#                 traceback.print_exc()\n",
    "#                 # logger.debug(f\"shape={datap.data3d.shape}, {datap.orientation_axcodes}\")\n",
    "#             # with open(fn_meta, \"w\") as f:\n",
    "#             #     json.dump(dict(row), f)\n",
    "#\n",
    "#\n",
    "#\n"
   ],
   "id": "6b87a9e1ec20b57c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "92447c2ea93d4b0d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
